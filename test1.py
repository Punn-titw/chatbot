import os
import re
import shutil
import logging
import pandas as pd
import chromadb
from dotenv import load_dotenv
from sentence_transformers import SentenceTransformer
from typing import List, Union
import google.generativeai as genai

# Set up logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# Load API Key
load_dotenv()
GENAI_API_KEY = "AIzaSyDqgBIeKpq9npG-En5zNk23AU-rY2kKt5s"
if not GENAI_API_KEY:
    raise ValueError("‚ö†Ô∏è ‡πÑ‡∏°‡πà‡∏û‡∏ö GOOGLE_API_KEY ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ API Key ‡∏Å‡πà‡∏≠‡∏ô!")

genai.configure(api_key=GENAI_API_KEY)
model = genai.GenerativeModel("gemini-pro")
embedding_model = SentenceTransformer("sentence-transformers/LaBSE")

class NCTEmbeddingFunction:
    def __init__(self, model):
        self.model = model
    
    def __call__(self, input: Union[str, List[str]]) -> List[List[float]]:
        return self.model.encode([input] if isinstance(input, str) else input, convert_to_tensor=False).tolist()

def reset_chroma_db(path: str):
    shutil.rmtree(path, ignore_errors=True)
    os.makedirs(path, exist_ok=True)
    logger.info(f"‚ú® Reset ChromaDB at {path}")

def prepare_data(df: pd.DataFrame) -> pd.DataFrame:
    df['id'] = df.apply(lambda row: f"{row['members']}_{hash(row['description'])}", axis=1)
    df['search_text'] = df.apply(lambda row: f"{row['members']} {row['description']}", axis=1)
    return df

def clean_text(text: str) -> str:
    return re.sub(r'\s+', ' ', text.lower().strip()) if isinstance(text, str) else ""

def load_data_to_chroma(df: pd.DataFrame, collection):
    for _, row in prepare_data(df).iterrows():
        collection.add(ids=[row['id']], documents=[clean_text(row['search_text'])], metadatas=[{"member": row['members'], "description": row['description']}])
    logger.info("‚ú® ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ñ‡∏π‡∏Å‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÉ‡∏ô ChromaDB ‡πÅ‡∏•‡πâ‡∏ß!")

def extract_member_name(query: str, members: List[str]) -> str:
    clean_q = clean_text(query)
    for member in members:
        if clean_text(member) in clean_q:
            return member
    return next((m for m in members if any(w in clean_q for w in clean_text(m).split() if len(w) > 2)), None)

def generate_with_gemini(query: str, member_name: str = None) -> str:
    prompt = f"‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö{' ' + member_name if member_name else ''}: \"{query}\"\n‡πÇ‡∏õ‡∏£‡∏î‡∏ï‡∏≠‡∏ö‡∏ï‡∏≤‡∏°‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏π‡πâ‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ‡∏´‡∏£‡∏∑‡∏≠‡πÅ‡∏à‡πâ‡∏á‡∏ß‡πà‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•"
    try:
        response = model.generate_content(prompt)
        return response.text.strip() if hasattr(response, 'text') else "‚ö†Ô∏è ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡πÑ‡∏î‡πâ"
    except Exception as e:
        logger.error(f"‚ùå ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö: {str(e)}")
        return "‚ö†Ô∏è ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö"

def format_answer(metadatas: List[dict], member_name: str, query: str) -> str:
    context = ' '.join(meta['description'] for meta in metadatas if clean_text(meta['member']) == clean_text(member_name))
    return generate_with_gemini(query, member_name) if not context else f"{member_name}: {context}"

def search_similar_members(query: str, members: List[str]) -> List[str]:
    clean_q = clean_text(query)
    return [m for m in members if any(w in clean_q for w in clean_text(m).split() if len(w) > 2)]

def rag_search(query: str, df: pd.DataFrame, collection):
    members = df['members'].unique().tolist()
    member_name = extract_member_name(query, members)
    
    if not member_name:
        similar_members = search_similar_members(query, members)
        suggestion = f"‚ö†Ô∏è ‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏ä‡∏∑‡πà‡∏≠‡∏™‡∏°‡∏≤‡∏ä‡∏¥‡∏Å‡∏ó‡∏µ‡πà‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô ‡∏Ñ‡∏∏‡∏ì‡∏´‡∏°‡∏≤‡∏¢‡∏ñ‡∏∂‡∏á: {', '.join(similar_members[:3])} ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà?"
        print(f"ü§ñ ‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö: {suggestion}" if similar_members else f"üîç ‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°: {query}\nü§ñ ‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö: {generate_with_gemini(query)}")
        return
    
    results = collection.query(query_texts=[f"{member_name} {clean_text(query)}"], n_results=5)
    answer = format_answer(results.get("metadatas", [{}])[0], member_name, query) if results.get("ids") else generate_with_gemini(query, member_name)
    print(f"üîç ‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°: {query}\nü§ñ ‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö: {answer}")

def interactive_qa(df: pd.DataFrame, collection):
    print("üé§ ‡∏£‡∏∞‡∏ö‡∏ö‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡∏™‡∏°‡∏≤‡∏ä‡∏¥‡∏Å NCT (‡∏û‡∏¥‡∏°‡∏û‡πå 'exit' ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏≠‡∏≠‡∏Å)")
    while (query := input("\n‚ùì ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏õ‡πâ‡∏≠‡∏ô‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°: ").strip().lower()) != 'exit':
        rag_search(query, df, collection) if query else print("‚ö†Ô∏è ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏õ‡πâ‡∏≠‡∏ô‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°")
    print("üëã ‡∏Ç‡∏≠‡∏ö‡∏Ñ‡∏∏‡∏ì‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡∏ö‡∏£‡∏¥‡∏Å‡∏≤‡∏£!")

if __name__ == "__main__":
    try:
        df = pd.read_csv("NEO - Sheet1.csv")
        reset_chroma_db("./chroma_nct")
        client = chromadb.PersistentClient(path="./chroma_nct")
        collection = client.create_collection(name="nct_members", embedding_function=NCTEmbeddingFunction(embedding_model))
        load_data_to_chroma(df, collection)
        interactive_qa(df, collection)
    except FileNotFoundError:
        logger.error("‚ùå ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• CSV")
        print("‚ùå ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• CSV")
    except Exception as e:
        logger.error(f"‚ùå ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î: {str(e)}")
        print(f"‚ùå ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î: {str(e)}")
